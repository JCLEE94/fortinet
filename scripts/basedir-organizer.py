#!/usr/bin/env python3
"""
Basedir Advanced Organizer - íŒŒì¼ëª… í‘œì¤€í™” ë° í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ë¦¬
"""
import os
import re
import shutil
import hashlib
from pathlib import Path
from typing import Dict, List, Set
import json

class BasedirOrganizer:
    def __init__(self, root_path="."):
        self.root = Path(root_path).resolve()
        self.changes = []
        self.duplicates = []
        
    def standardize_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì„ kebab-caseë¡œ í‘œì¤€í™”"""
        # React ì»´í¬ë„ŒíŠ¸ëŠ” PascalCase ìœ ì§€
        if filename.endswith(('.tsx', '.jsx')) and filename[0].isupper():
            return filename
            
        # ì„¤ì • íŒŒì¼ì€ lowercase ìœ ì§€
        if filename.startswith('.') or filename in ['tsconfig.json', 'package.json']:
            return filename
            
        # íŠ¹ìˆ˜ë¬¸ìì™€ ê³µë°±ì„ í•˜ì´í”ˆìœ¼ë¡œ ë³€í™˜
        name, ext = os.path.splitext(filename)
        name = re.sub(r'[\s_]+', '-', name)  # ê³µë°±ê³¼ ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ í•˜ì´í”ˆìœ¼ë¡œ
        name = re.sub(r'[^\w\-]', '', name)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        name = name.lower()  # ì†Œë¬¸ìë¡œ
        name = re.sub(r'-+', '-', name)  # ì¤‘ë³µ í•˜ì´í”ˆ ì œê±°
        name = name.strip('-')  # ì•ë’¤ í•˜ì´í”ˆ ì œê±°
        
        return f"{name}{ext}" if name else filename
        
    def find_duplicates(self) -> List[Dict]:
        """MD5 í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ íŒŒì¼ ì°¾ê¸°"""
        file_hashes = {}
        
        for file_path in self.root.rglob('*'):
            if file_path.is_file() and '.git' not in str(file_path):
                try:
                    with open(file_path, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                        
                    if file_hash in file_hashes:
                        self.duplicates.append({
                            'original': str(file_hashes[file_hash]),
                            'duplicate': str(file_path),
                            'hash': file_hash
                        })
                    else:
                        file_hashes[file_hash] = file_path
                except Exception as e:
                    print(f"Error reading {file_path}: {e}")
                    
        return self.duplicates
        
    def organize_structure(self):
        """í”„ë¡œì íŠ¸ êµ¬ì¡° ì¬êµ¬ì„±"""
        moves = []
        
        # scripts ë””ë ‰í† ë¦¬ë¡œ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì´ë™
        for file_path in self.root.rglob('*.sh'):
            if 'scripts' not in str(file_path) and '.git' not in str(file_path):
                target = self.root / 'scripts' / file_path.name
                moves.append((file_path, target))
                
        # configs ë””ë ‰í† ë¦¬ë¡œ ì„¤ì • íŒŒì¼ ì´ë™
        config_patterns = ['*config*.json', '*config*.yaml', '*config*.yml', '.env*']
        for pattern in config_patterns:
            for file_path in self.root.glob(pattern):
                if 'configs' not in str(file_path):
                    target = self.root / 'configs' / file_path.name
                    moves.append((file_path, target))
                    
        return moves
        
    def clean_backup_files(self):
        """ë°±ì—… ë° ì„ì‹œ íŒŒì¼ ì‚­ì œ"""
        patterns = ['*-backup*', '*-old*', '*-copy*', '*.bak', '*~', '*.tmp']
        removed = []
        
        for pattern in patterns:
            for file_path in self.root.rglob(pattern):
                if '.git' not in str(file_path):
                    removed.append(str(file_path))
                    
        return removed
        
    def execute(self, dry_run=True):
        """ì‹¤í–‰ (dry_run=Trueë©´ ë¯¸ë¦¬ë³´ê¸°ë§Œ)"""
        results = {
            'standardized': [],
            'duplicates': self.find_duplicates(),
            'structure_changes': self.organize_structure(),
            'removed_backups': self.clean_backup_files()
        }
        
        # íŒŒì¼ëª… í‘œì¤€í™”
        for file_path in self.root.rglob('*'):
            if file_path.is_file() and '.git' not in str(file_path):
                old_name = file_path.name
                new_name = self.standardize_filename(old_name)
                
                if old_name != new_name:
                    new_path = file_path.parent / new_name
                    results['standardized'].append({
                        'old': str(file_path),
                        'new': str(new_path)
                    })
                    
                    if not dry_run and not new_path.exists():
                        file_path.rename(new_path)
                        
        if not dry_run:
            # ì¤‘ë³µ íŒŒì¼ ì‚­ì œ
            for dup in results['duplicates']:
                Path(dup['duplicate']).unlink()
                
            # ë°±ì—… íŒŒì¼ ì‚­ì œ
            for backup in results['removed_backups']:
                Path(backup).unlink()
                
            # êµ¬ì¡° ë³€ê²½ ì‹¤í–‰
            for src, dst in results['structure_changes']:
                dst.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(src), str(dst))
                
        return results

if __name__ == "__main__":
    import sys
    
    organizer = BasedirOrganizer()
    
    if len(sys.argv) > 1 and sys.argv[1] == "--execute":
        print("ğŸš€ ì‹¤ì œ ì •ë¦¬ ì‹¤í–‰ ì¤‘...")
        results = organizer.execute(dry_run=False)
    else:
        print("ğŸ“‹ ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ (ì‹¤ì œ ë³€ê²½ ì—†ìŒ)")
        results = organizer.execute(dry_run=True)
        
    print(f"\nğŸ“Š ì •ë¦¬ ê²°ê³¼:")
    print(f"  - í‘œì¤€í™”í•  íŒŒì¼: {len(results['standardized'])}ê°œ")
    print(f"  - ì¤‘ë³µ íŒŒì¼: {len(results['duplicates'])}ê°œ")
    print(f"  - êµ¬ì¡° ë³€ê²½: {len(results['structure_changes'])}ê°œ")
    print(f"  - ì‚­ì œí•  ë°±ì—…: {len(results['removed_backups'])}ê°œ")
    
    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    with open('basedir-cleanup-report.json', 'w') as f:
        json.dump(results, f, indent=2, default=str)
    print(f"\nâœ… ìƒì„¸ ë¦¬í¬íŠ¸: basedir-cleanup-report.json")